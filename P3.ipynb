{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784) (5000, 784)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "train = list()\n",
    "test = list()\n",
    "\n",
    "for i in range(10):\n",
    "    train.append(np.array(pd.read_csv('Part3_%d_Train.csv'%i, header=None)))\n",
    "    test.append(np.array(pd.read_csv('Part3_%d_Test.csv'%i, header=None)))\n",
    "\n",
    "np.random.seed(21)\n",
    "X_train = np.vstack(train)\n",
    "y_train = np.concatenate([np.tile(i, train[i].shape[0]) for i in range(10)])\n",
    "idx_train = np.array(range(X_train.shape[0]))\n",
    "np.random.shuffle(idx_train)\n",
    "X_train = X_train[idx_train]\n",
    "y_train = y_train[idx_train]\n",
    "\n",
    "X_test = np.vstack(test)\n",
    "y_test = np.concatenate([np.tile(i, test[i].shape[0]) for i in range(10)])\n",
    "idx_test = np.array(range(X_test.shape[0]))\n",
    "np.random.shuffle(idx_test)\n",
    "X_test = X_test[idx_test]\n",
    "y_test = y_test[idx_test]\n",
    "\n",
    "enc = np.eye(2)\n",
    "def one_hot(d):\n",
    "    return enc[d]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 197) (10, 7745)\n"
     ]
    }
   ],
   "source": [
    "from skimage.util import view_as_windows, view_as_blocks\n",
    "W_conv = np.zeros((16, (7+21)*7+1))\n",
    "W_out = np.empty((10, 22*22*16+1))\n",
    "\n",
    "class seeded_session:\n",
    "    def __enter__(self):\n",
    "        np.random.seed(25523)\n",
    "        global W_conv, W_out\n",
    "        padded_weights = W_conv[:, :-1].reshape((-1, 7, 28))\n",
    "        padded_weights[:, :, :7] = np.random.rand(16, 7, 7)*1e-5\n",
    "        padded_weights[:, :, 7:] = 0.0\n",
    "        W_conv[:, -1:] = np.random.rand(16, 1)*1e-5\n",
    "        W_out[:] = np.random.rand(*W_out.shape)\n",
    "        return W_conv, W_out\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "\n",
    "with seeded_session():\n",
    "    print(W_conv.shape, W_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 2, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.zeros((5,5))\n",
    "from skimage.util import view_as_windows, view_as_blocks\n",
    "view_as_windows(A, (2,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([0, 1])\n",
    "bb = np.block([aa, aa])\n",
    "bb[-1] = 2\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08167216  0.06723635  0.06784451  0.12499845  0.10929     0.10653567\n",
      "  0.13443319  0.13235481  0.06826789  0.10736697] 6\n",
      "[ 0.08157977  0.06735625  0.06782699  0.12476304  0.10946821  0.10648655\n",
      "  0.13444601  0.1322562   0.06827485  0.10754213] 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "CONV7_OFFSETS = list(itertools.chain(*[range(ii*28,ii*28+22) for ii in range(22)]))\n",
    "\n",
    "def conv7(w):\n",
    "    \"\"\" 7x7 convolution in matrix form \"\"\"\n",
    "    def forward1(x):\n",
    "        convmat = np.block([\n",
    "            #                 vvv throw away final padding & bias\n",
    "            [np.zeros(jj), w[:-(21+1)], np.zeros(28*28-(7*28-21)-jj)]\n",
    "                #   vvv starting position of the kernel\n",
    "                for jj in CONV7_OFFSETS\n",
    "        ])\n",
    "        return np.tanh(np.dot(convmat, x) + w[-1])\n",
    "    def forward2(x):\n",
    "        row = []\n",
    "        for ii in range(22):\n",
    "            convmat = np.block([\n",
    "                #                 vvv throw away final padding & bias\n",
    "                [np.zeros(jj), w[:-(21+1)], np.zeros(28*28-(7*28-21)-jj)]\n",
    "                    #   vvv starting position of the kernel\n",
    "                    for jj in range(ii*28,ii*28+22)\n",
    "            ])\n",
    "            row.extend(np.dot(convmat, x))\n",
    "        return np.tanh(np.array(row) + w[-1])\n",
    "    def forward3(x):\n",
    "        convmat = np.block([\n",
    "            #                 vvv throw away final padding & bias\n",
    "            [np.zeros(jj), w[:-(21+1)], np.zeros(21-jj)]\n",
    "                #   vvv starting position of the kernel\n",
    "                for jj in range(22)\n",
    "        ])\n",
    "        row = np.array([np.dot(convmat, x[ii*28:ii*28+7*28]) for ii in range(22)])\n",
    "        return np.tanh(row + w[-1])\n",
    "    # === above impls are correct, but to accelerate, I use forward0 ===\n",
    "    def forward0(x):\n",
    "        return np.tanh(convolve2d(\n",
    "            x.reshape(28, 28),\n",
    "            w[:-1].reshape((7, 28))[:, :7],\n",
    "            mode='valid').ravel() + w[-1])\n",
    "    return forward3\n",
    "\n",
    "def softmax(x):\n",
    "    a = np.exp(x)\n",
    "    return a / np.sum(a)\n",
    "\n",
    "def perceptron(w):\n",
    "    return lambda x: np.dot(w[:-1], x) + w[-1]\n",
    "\n",
    "conv_filters = [conv7(w) for w in W_conv]\n",
    "conv_layer = lambda x: np.array([f(x) for f in conv_filters])\n",
    "output_neurons = [perceptron(w) for w in W_out]\n",
    "fc_layer = lambda x: softmax([f(x.ravel()) for f in output_neurons])\n",
    "model = lambda x: fc_layer(conv_layer(x))\n",
    "\n",
    "with seeded_session():\n",
    "    for k in range(2):\n",
    "        plt.figure()\n",
    "        plt.imshow(X_train[k].reshape(28, 28).T)\n",
    "        print(model(X_train[k]), y_train[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "\n",
    "Assuming loss function: $ \\text{loss}(\\mathbf{y}) = -\\sum_j { d_j \\log y_j } $\n",
    "\n",
    "**Output layer**\n",
    "\n",
    "$$\n",
    "\\delta_j^H = \\frac{\\partial E}{\\partial \\nu_j^H} = -e_j\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta w_{ij}^H = -\\alpha \\delta_j^H y_i^{H-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta b_j^H = -\\alpha \\delta_j^H\n",
    "$$\n",
    "\n",
    "**Hidden layer**\n",
    "\n",
    "$$\n",
    "\\delta_j^h = \\frac{\\partial E}{\\partial \\nu_j^h} = \\left( \\sum_{l = 1}^{L^{h+1}} \\frac{\\partial E}{\\partial \\nu_l^{h+1}} \\frac{\\partial \\nu_l^{h+1}}{\\partial y_j^h} \\right) \\frac{\\partial y_j^h}{\\partial \\nu_j^h}\n",
    "=\\left( \\sum_{l = 1}^{L^{h+1}} {\\delta_l^H w_{jl}^H} \\right) (1-(y_j^h)^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta w_{i}^h = -\\alpha \\sum_{j=1}^{L^0} {\\delta_j^h \\frac{\\partial \\nu_j^h}{\\partial w_i^h}}\n",
    "=-\\alpha \\sum_{j=1}^{L^0} {\\delta_j^h  {x_{j+i-1}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta b^h = -\\alpha \\sum_{j=1}^{L^0} {\\delta_j^h \\frac{\\partial \\nu_j^h}{\\partial b^h}}\n",
    "=-\\alpha \\sum_{j=1}^{L^0} {\\delta_j^h }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(x, d, alpha):\n",
    "    y_conv = conv_layer(x) # shape: (filter, spatial) = (2, 1)\n",
    "    y_output = fc_layer(y_conv) # shape: (neuron, ) = (2, )\n",
    "    e = one_hot(d) - y_output\n",
    "    # delta_out.shape == y_output.shape\n",
    "    delta_out = -e\n",
    "    # W_out.shape: (neuron: j, [out] weights+bias: i) = (2, 2+1)\n",
    "    update_out = -alpha * np.outer(delta_out, np.append(np.ravel(y_conv), 1.0))\n",
    "    # delta_conv.shape == y_conv.shape\n",
    "    #                        vvvv output weights without any bias\n",
    "    delta_conv = (np.dot(W_out[:, :-1].T, delta_out) * np.ravel(1-y_conv**2)).reshape(y_conv.shape)\n",
    "    # W_conv.shape: (filter, [conv] weights+bias) = (2, 28*28+1)\n",
    "    update_conv = np.zeros(W_conv.shape)\n",
    "    for idx_filter in range(update_conv.shape[0]):\n",
    "        update_conv[idx_filter, :] = -alpha * np.array(\n",
    "            [np.dot(delta_conv[idx_filter], x[i: i+delta_conv.shape[1]])\n",
    "                for i in range(W_conv.shape[1]-1)] +\n",
    "            [np.sum(delta_conv[idx_filter])]\n",
    "        )\n",
    "    return {k:v for k,v in locals().items() if k not in set(['x'])}\n",
    "\n",
    "with seeded_session():\n",
    "    pprint(train_one(X_train[0], y_train[0], 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autograd(params, f):\n",
    "    epsilon = 1e-6\n",
    "    backup = params.copy().ravel()\n",
    "    grad = np.empty(params.shape)\n",
    "    for i in range(len(backup)):\n",
    "        params.flat[i] = backup[i] + epsilon\n",
    "        f1 = f()\n",
    "        params.flat[i] = backup[i] - epsilon\n",
    "        f2 = f()\n",
    "        grad.flat[i] = (f1-f2)/(epsilon*2.0)\n",
    "        params.flat[i] = backup.flat[i]\n",
    "    return grad\n",
    "\n",
    "def train_one_autodiff(x, d, alpha):\n",
    "    loss = lambda x, d: -np.sum(one_hot(d)*np.log(model(x)))\n",
    "    update_out = -alpha * autograd(W_out, lambda: loss(x, d))\n",
    "    update_conv = -alpha * autograd(W_conv, lambda: loss(x, d))\n",
    "    return {k:v for k,v in locals().items() if k not in set(['x', 'loss'])}\n",
    "\n",
    "with seeded_session():\n",
    "    pprint(train_one_autodiff(X_train[0], y_train[0], 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "vacc = []\n",
    "epochs = 25\n",
    "\n",
    "progress = IntProgress(description='epoch', min=0, max=epochs-1)\n",
    "display(progress)\n",
    "\n",
    "with seeded_session():\n",
    "    for i_epoch in range(epochs):\n",
    "        epoch_loss = []\n",
    "        epoch_acc = []\n",
    "        for x, d in zip(X_train, y_train):\n",
    "            v = train_one(x, d, 0.001)\n",
    "            epoch_loss.append(-np.sum(one_hot(d)*np.log(v['y_output'])))\n",
    "            epoch_acc.append(np.argmax(v['y_output']) == d)\n",
    "            W_conv += v['update_conv']\n",
    "            W_out += v['update_out']\n",
    "        acc.append(np.mean(epoch_acc))\n",
    "        loss.append(np.mean(epoch_loss))\n",
    "        epoch_vacc = []\n",
    "        for x, d in zip(X_test, y_test):\n",
    "            y = model(x)\n",
    "            epoch_vacc.append(np.argmax(y) == d)\n",
    "        vacc.append(np.mean(epoch_vacc))\n",
    "        progress.value = i_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(epochs)), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(epochs)), acc, label='acc')\n",
    "plt.plot(list(range(epochs)), vacc, label='vacc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W_conv[0, :-1].reshape(28, 28).T)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W_conv[1, :-1].reshape(28, 28).T)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
