{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_reader(part):\n",
    "    for i in range(10):\n",
    "        with open('Part3_{}_{}.csv'.format(i, part)) as f:\n",
    "            for line in f:\n",
    "                yield line.strip(), i\n",
    "\n",
    "def mnist_decoder(csv_line, label):\n",
    "    FIELD_DEFAULTS = [[0.0]]*(28*28)\n",
    "    with tf.variable_scope('DataSource'):\n",
    "        fields = tf.decode_csv(csv_line, FIELD_DEFAULTS)\n",
    "        im = tf.stack(fields)\n",
    "        im = tf.reshape(im, (28, 28))\n",
    "        return im, tf.one_hot(label, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope('DataSource'):\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: mnist_reader('Train'),\n",
    "        # csv_line, label\n",
    "        (tf.string, tf.int32),\n",
    "        (tf.TensorShape([]), tf.TensorShape([])\n",
    "    )).map(mnist_decoder, num_parallel_calls=2) \\\n",
    "      .batch(50) \\\n",
    "      .prefetch(1) \\\n",
    "      .repeat(epochs)\n",
    "    \n",
    "    dataset_val = tf.data.Dataset.from_generator(lambda: mnist_reader('Test'),\n",
    "        (tf.string, tf.int32),\n",
    "        (tf.TensorShape([]), tf.TensorShape([])\n",
    "    )).map(mnist_decoder, num_parallel_calls=2) \\\n",
    "      .batch(50) \\\n",
    "      .prefetch(1)\n",
    "\n",
    "    iter_handle = tf.placeholder(tf.string, shape=[])\n",
    "    data_iterator = tf.data.Iterator.from_string_handle(iter_handle, dataset.output_types, dataset.output_shapes)\n",
    "    train_iterator = dataset.make_one_shot_iterator()\n",
    "    val_iterator = dataset_val.make_initializable_iterator()\n",
    "    val_init_op = data_iterator.make_initializer(dataset_val)\n",
    "    images, onehot_labels = data_iterator.get_next()\n",
    "\n",
    "with tf.variable_scope('Initializer'):\n",
    "    init_global = tf.global_variables_initializer()\n",
    "    init_local = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3ee0f3bcfe43fca1d78b33e6410645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='epoch', max=49)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd44a12a8991425b8eb86a2da2343b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='step', max=99)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4387cc6c2e13416b81328d8256fdef9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='val_step', max=99)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "progress_epoch = IntProgress(description='epoch', min=0, max=epochs-1)\n",
    "progress_step = IntProgress(description='step', min=0, max=5000//epochs-1)\n",
    "progress_valstep = IntProgress(description='val_step', min=0, max=5000//epochs-1)\n",
    "display(progress_epoch)\n",
    "display(progress_step)\n",
    "display(progress_valstep)\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=2,\n",
    "    inter_op_parallelism_threads=2,\n",
    "    allow_soft_placement=True)\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(init_global)\n",
    "    train_handle = sess.run(train_iterator.string_handle())\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    for epoch in range(epochs):\n",
    "        progress_epoch.value = epoch\n",
    "        steps_per_epoch = 5000//epochs\n",
    "        sess.run(init_local)\n",
    "        for step in range(steps_per_epoch):\n",
    "            progress_step.value = step\n",
    "            sess.run([images, onehot_labels], feed_dict={iter_handle: train_handle})\n",
    "            \n",
    "        sess.run([init_local, val_init_op], feed_dict={iter_handle: val_handle})\n",
    "        for val_step in range(steps_per_epoch):\n",
    "            progress_valstep.value = val_step\n",
    "            sess.run([images, onehot_labels], feed_dict={iter_handle: val_handle})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
